{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e85844-99c1-4581-961b-d2f74bf9f5b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TIM Python Client - KPI Driven Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365dc574-2bd4-4f63-8759-a78069e988ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34861c40-5edc-4a13-a691-0cc5ad14f847",
   "metadata": {},
   "source": [
    "Import the libraries necessary to run this notebook and set up the python client for TIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4db770-14bd-44bb-a764-4561f32b3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import plotly as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as splt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf38127-6c3a-4988-917a-e4812d53d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_path = os.path.dirname(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b761578-ef42-4b77-b2f7-6d85fb94d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tim\n",
    "tim_credentials = json.load(open(tutorial_path+'/tim_credentials.json'))\n",
    "client = tim.Tim(email=tim_credentials['email'],password=tim_credentials['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701754f-a632-4eba-bab1-0a67c0d44414",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9289900-b763-4494-adb6-45885d319c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Datetime', 'Output', 'AmbientHumidity', 'AmbientTemperature',\n",
      "       'M1_RawMaterial_1', 'M1_RawMaterial_2', 'M1_RawMaterial_3',\n",
      "       'M1_RawMaterial_4', 'M1_RawMaterialFeeder', 'M1_Zone1_Temperature',\n",
      "       'M1_Zone2_Temperature', 'M1_MotorAmperage', 'M1_MotorRPM',\n",
      "       'M1_MaterialPressure', 'M1_MaterialTemperature',\n",
      "       'M1_ExitZoneTemperature', 'M2_RawMaterial_1', 'M2_RawMaterial_2',\n",
      "       'M2_RawMaterial_3', 'M2_RawMaterial_4', 'M2_RawMaterialFeeder',\n",
      "       'M2_Zone1_Temperature', 'M2_Zone2_Temperature', 'M2_MotorAmperage',\n",
      "       'M2_MotorRPM', 'M2_MaterialPressure', 'M2_MaterialTemperature',\n",
      "       'M2_ExitZoneTemperature', 'M3_RawMaterial_1', 'M3_RawMaterial_2',\n",
      "       'M3_RawMaterial_3', 'M3_RawMaterial_4', 'M3_RawMaterialFeeder',\n",
      "       'M3_Zone1_Temperature', 'M3_Zone2_Temperature', 'M3_MotorAmperage',\n",
      "       'M3_MotorRPM', 'M3_MaterialPressure', 'M3_MaterialTemperature',\n",
      "       'M3_ExitZoneTemperature', 'Stage_1_Temperature1',\n",
      "       'Stage_1_Temperature2', 'Stage_1_Temperature3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "csv_df = pd.read_csv(tutorial_path+'/datasets/production_line.csv')\n",
    "print(csv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7cdf68a-ce0c-429b-a85e-a6abd4fdfc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_dataset = csv_df.copy()\n",
    "timestamp = 'Datetime'\n",
    "target = 'Output'\n",
    "predictors = [s for s in list(tim_dataset.columns) if s not in [timestamp,target]]\n",
    "tim_dataset = tim_dataset[[timestamp,target]+predictors].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ab59a-875a-4226-864e-eaadbbdebb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = tim_dataset.copy()\n",
    "fig = splt.make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[target], name=target,connectgaps=True), row=1, col=1)\n",
    "for idx, p in enumerate(predictors): fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[p], name=p,connectgaps=True), row=2, col=1)\n",
    "fig.update_layout(height=600, width=1200, title_text=\"Data visualization\")\n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da646335-3765-4abc-bb48-dbd4451c00cb",
   "metadata": {},
   "source": [
    "# 2. TIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f07b1-e0c4-4ef2-a119-772b9053be2c",
   "metadata": {},
   "source": [
    "## 2.1 Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e99f2f-39b1-49e2-b7ec-56d9b961bc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect dataset\n",
      "Use Case Created\n",
      "Experiment created\n"
     ]
    }
   ],
   "source": [
    "tim_workspace = json.load(open(tutorial_path+'/tim_workflow/tim_workspace.json'))\n",
    "workspace_id = tim_workspace['id']\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "pipeline = {\n",
    "    'dataset':'production_line',\n",
    "    'use_case':'KPI driven anomaly detection',\n",
    "    'experiment':'KPI driven anomaly detection'\n",
    "}\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "try:\n",
    "    dataset_list = [f for f in client.datasets.list_dataset(workspace_id=workspace_id) if f['name']==pipeline['dataset']]\n",
    "    tim_upload = dataset_list[0]\n",
    "    dataset_id = tim_upload['id']\n",
    "    print(\"Collect dataset\")\n",
    "except:\n",
    "    now_dt = dt.datetime.now()\n",
    "    upload_dataset_configuration = {\n",
    "        \"name\": pipeline['dataset'],\n",
    "        \"workspace\": {\n",
    "            \"id\": workspace_id\n",
    "        },\n",
    "        \"versionName\": now_dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    tim_upload = client.upload_dataset(\n",
    "        dataset = tim_dataset,\n",
    "        configuration = upload_dataset_configuration,\n",
    "        wait_to_finish = True,\n",
    "        outputs = ['response'],\n",
    "        status_poll = print,\n",
    "        tries_left = 300\n",
    "    )\n",
    "    print(\"dataset uploaded\")\n",
    "    dataset_id = tim_upload.response['id']\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "try:\n",
    "    use_case_list = [f for f in client.use_cases.list_use_case(dataset_id = dataset_id) if f['name']==pipeline['use_case']]\n",
    "    tim_use_case = use_case_list[0]\n",
    "    print(\"Collect Use Case\")\n",
    "except:\n",
    "    create_use_case_configuration = {\n",
    "        \"name\": pipeline['use_case'],\n",
    "        \"workspace\": {\n",
    "            \"id\": workspace_id\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"id\": dataset_id\n",
    "        },\n",
    "    }\n",
    "    tim_use_case = client.use_cases.create_use_case(configuration=create_use_case_configuration)\n",
    "    print(\"Use Case Created\")\n",
    "use_case_id = tim_use_case['id']\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "try:\n",
    "    experiment_list = [f for f in client.experiments.list_experiment(use_case_id = use_case_id) if f['name']==pipeline['experiment']]\n",
    "    tim_experiment = experiment_list[0]\n",
    "    print(\"Collect experiment\")\n",
    "except:\n",
    "    create_experiment_configuration = {\n",
    "      \"name\": pipeline['experiment'],\n",
    "      \"useCase\": {\n",
    "        \"id\": use_case_id\n",
    "      },\n",
    "      \"type\": \"AnomalyDetection\"\n",
    "    }\n",
    "    tim_experiment = client.experiments.create_experiment(configuration=create_experiment_configuration)\n",
    "    print(\"Experiment created\")\n",
    "experiment_id = tim_experiment['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc7dce-4bb6-44a1-bf56-00d4d133e673",
   "metadata": {},
   "source": [
    "## 2.2 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0f5eb-e266-4f1a-96dc-236c265de5b9",
   "metadata": {},
   "source": [
    "### 2.2.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d637f780-a5d1-4252-8082-cc22af7af775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'KPI driven anomaly detection',\n",
       " 'useCase': {'id': '25dfe2fa-b459-4e89-be4c-aa74f4fa0f83'},\n",
       " 'experiment': {'id': '94f45879-ae97-46e2-8c2d-0f51e7e93187'},\n",
       " 'data': {'rows': {'type': 'First', 'baseUnit': 'Sample', 'value': 9392}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_rows = int(len(tim_dataset)*2/3)\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "detection_build_kpi_model_configuration = {\n",
    "    \"name\": \"KPI driven anomaly detection\",\n",
    "    \"useCase\": {\"id\": use_case_id},\n",
    "    \"experiment\": {\"id\": experiment_id},\n",
    "#     \"configuration\": {\n",
    "#         \"domainSpecifics\": [\n",
    "#             {\n",
    "#                 \"perspective\": \"Residual\",\n",
    "#                 \"sensitivity\": 0,\n",
    "#                 \"minSensitivity\": 0,\n",
    "#                 \"maxSensitivity\": 0\n",
    "#             }\n",
    "#         ],\n",
    "#         \"normalBehaviorModel\": {\n",
    "#             \"useNormalBehaviorModel\": True,\n",
    "#             \"normalization\": True,\n",
    "#             \"maxModelComplexity\": 50,\n",
    "#             \"features\": [\n",
    "#                 \"ExponentialMovingAverage\",\n",
    "#                 \"TimeOffsets\",\n",
    "#                 \"Identity\",\n",
    "#                 \"Intercept\"\n",
    "#             ],\n",
    "#             \"dailyCycle\": true,\n",
    "#             \"useKPIoffsets\": true,\n",
    "#             \"allowOffsets\": true,\n",
    "#             \"offsetLimit\": {\"type\": \"Explicit\",\"value\": 0}\n",
    "#         },\n",
    "#         \"anomalousBehaviorModel\": {\n",
    "#             \"maxModelComplexity\": 15,\n",
    "#             \"detectionIntervals\": [\n",
    "#                 {\"type\": \"Hour\",\"value\": \"8-16\"}\n",
    "#             ]\n",
    "#         }\n",
    "#     },\n",
    "    \"data\": {\n",
    "#         \"version\": {\"id\": \"a74ae716-a86e-47f0-8a50-d8b21d6d7dd6\"},\n",
    "        \"rows\": {\"type\":\"First\",\"baseUnit\": \"Sample\",\"value\": in_sample_rows}, #{\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1} or [{\"from\": \"yyyy-mm-dd HH:MM:SS\",\"to\": \"yyyy-mm-dd HH:MM:SS\"}]\n",
    "#         \"columns\": [\n",
    "#             1,\n",
    "#             3,\n",
    "#             \"wind_speed\"\n",
    "#         ],\n",
    "#         \"KPIColumn\": \"rotor_speed\",\n",
    "#         \"holidayColumn\": \"PH\",\n",
    "#         \"labelColumn\": \"LABEL\",\n",
    "#         \"imputation\": {\"type\": \"LOCF\",\"maxGapLength\": 6},\n",
    "#         \"timeScale\": {\"baseUnit\": \"Hour\",\"value\": 1},\n",
    "#         \"aggregation\": \"Mean\",\n",
    "#         \"updates\": [\n",
    "#             {\n",
    "#                 \"column\": \"wind_speed\",\n",
    "#                 \"updateTime\": [\n",
    "#                     {\"type\": \"Hour\",\"value\": \"1,12,23\"}\n",
    "#                 ],\n",
    "#                 \"updateUntil\": {\"baseUnit\": \"Hour\",\"offset\": -2}\n",
    "#             }\n",
    "#         ]\n",
    "    }\n",
    "}\n",
    "detection_build_kpi_model_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf132d96-e78a-49b6-868b-b6fa1c2637d3",
   "metadata": {},
   "source": [
    "### 2.2.2 API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab33304a-e93e-4794-88f5-354aee708211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'createdAt': '2023-04-20T15:26:48.746Z'}\n",
      "{'status': 'Running', 'progress': 13.0, 'CPU': 0.06, 'memory': 3571.0, 'createdAt': '2023-04-20T15:26:51.469Z'}\n",
      "{'status': 'Running', 'progress': 60.0, 'CPU': 0.06, 'memory': 3568.0, 'createdAt': '2023-04-20T15:26:53.477Z'}\n",
      "{'status': 'Running', 'progress': 60.0, 'CPU': 0.06, 'memory': 3568.0, 'createdAt': '2023-04-20T15:26:53.477Z'}\n",
      "{'status': 'Running', 'progress': 77.5, 'CPU': 0.14, 'memory': 3736.0, 'createdAt': '2023-04-20T15:26:56.724Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.45, 'memory': 3742.0, 'createdAt': '2023-04-20T15:26:59.197Z'}\n"
     ]
    }
   ],
   "source": [
    "detection_build_kpi_model = client.extended_detection.build_kpi_model(\n",
    "    configuration = detection_build_kpi_model_configuration,\n",
    "    # dataset_id = dataset_id,\n",
    "    # execute = True,\n",
    "    # wait_to_finish = True,\n",
    "    outputs = [\n",
    "        'id',\n",
    "        'details',\n",
    "        'logs',\n",
    "        'status',\n",
    "        'table',\n",
    "        'model',\n",
    "        'accuracies'\n",
    "    ],\n",
    "    status_poll = print,\n",
    "    # tries_left = 300\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af8b7b79-6a86-49b4-a660-ceab87f9dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_build_kpi_model_id = detection_build_kpi_model.id\n",
    "detection_build_kpi_model_details = detection_build_kpi_model.details\n",
    "detection_build_kpi_model_logs = detection_build_kpi_model.logs\n",
    "detection_build_kpi_model_status = detection_build_kpi_model.status\n",
    "detection_build_kpi_model_table = detection_build_kpi_model.table\n",
    "detection_build_kpi_model_model = detection_build_kpi_model.model\n",
    "detection_build_kpi_model_accuracies = detection_build_kpi_model.accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefad87-0110-4196-b866-e01d485d4d9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3 Detection Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801cf90-7f94-4201-9a68-7f6b910256af",
   "metadata": {},
   "source": [
    "### 2.3.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd2b44e-f1a4-41ef-ab86-7e91b37daf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sample_rows = int(len(tim_dataset)-in_sample_rows)\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "detection_detect_configuration = {\n",
    "#     \"name\": \"My first anomaly detect job\",\n",
    "    \"experiment\": {\"id\":experiment_id},\n",
    "    \"data\": {\n",
    "#         \"version\": {\"id\": \"a74ae716-a86e-47f0-8a50-d8b21d6d7dd6\"},\n",
    "        \"rows\": {\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": out_sample_rows}, #{\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1} or [{\"from\": \"yyyy-mm-dd HH:MM:SS\",\"to\": \"yyyy-mm-dd HH:MM:SS\"}]\n",
    "#         \"imputation\": {\"type\": \"LOCF\",\"maxGapLength\": 6}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d27b08-efbd-4567-9177-d2f5c01f732c",
   "metadata": {},
   "source": [
    "### 2.3.2 API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4bd5cd-1af6-4d27-9d1a-f76a1f29461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'createdAt': '2023-04-20T15:27:52.206Z'}\n",
      "{'status': 'Running', 'progress': 53.19, 'CPU': 0.29, 'memory': 3561.0, 'createdAt': '2023-04-20T15:27:55.407Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.29, 'memory': 3575.0, 'createdAt': '2023-04-20T15:27:56.452Z'}\n"
     ]
    }
   ],
   "source": [
    "detection_detect = client.detection_detect(\n",
    "    parent_job_id = detection_build_kpi_model_id,\n",
    "    configuration = detection_detect_configuration,\n",
    "    # execute = True,\n",
    "    # wait_to_finish = True,\n",
    "    outputs = [\n",
    "        'id',\n",
    "        'details',\n",
    "        'logs',\n",
    "        'status',\n",
    "        'table',\n",
    "        'model',\n",
    "        'accuracies',\n",
    "        'production_table',  \n",
    "    ],\n",
    "    status_poll = print,\n",
    "    # tries_left = 300\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34abf08c-dfe8-40c3-95b7-56f141b40f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_detect_id = detection_detect.id\n",
    "detection_detect_details = detection_detect.details\n",
    "detection_detect_logs = detection_detect.logs\n",
    "detection_detect_status = detection_detect.status\n",
    "detection_detect_table = detection_detect.table\n",
    "detection_detect_model = detection_detect.model\n",
    "detection_detect_accuracies = detection_detect.accuracies\n",
    "detection_detect_production_table = detection_detect.production_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265d67a-c4dd-41db-97a9-be3742fdb5bc",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "045bc035-675e-4b9b-9bbe-1df36da08dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_df = client.post_process.properties(detection_build_kpi_model_model)\n",
    "features_df = client.post_process.features(detection_build_kpi_model_model)\n",
    "model_logs_df = pd.DataFrame(detection_build_kpi_model_logs).sort_values(by='createdAt').reset_index(drop=True)\n",
    "detect_logs_df = pd.DataFrame(detection_detect_logs).sort_values(by='createdAt').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4b814-4e30-4077-9a8f-37f0bdd63840",
   "metadata": {},
   "source": [
    "## 3.1 Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a58e9-9cc7-4491-b7dc-2320a9ff4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = splt.make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig.add_trace(go.Scatter(x=tim_dataset[timestamp], y=tim_dataset[target], name=target, line=dict(color='black')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=detection_build_kpi_model_table['timestamp'], y=detection_build_kpi_model_table['normal_behavior'], name='InSample Normal Behavior', line=dict(color='goldenrod')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=detection_detect_table['timestamp'], y=detection_detect_table['normal_behavior'], name='OutOfSample Normal Behavior', line=dict(color='darkgoldenrod')), row=1, col=1)\n",
    "for ai in [f for f in detection_build_kpi_model_table.columns if 'anomaly_indicator' in f]:\n",
    "    fig.add_trace(go.Scatter(x=detection_build_kpi_model_table['timestamp'], y=detection_build_kpi_model_table[ai], name= ai.replace('anomaly_indicator_','')+' InSample'), row=2, col=1)\n",
    "    va = detection_build_kpi_model_table[detection_build_kpi_model_table[ai]>=1]\n",
    "    fig.add_trace(go.Scatter(x=va['timestamp'], y=va['kpi'], name=ai.replace('anomaly_indicator_','')+' anomaly inSample',mode='markers', line={'color': 'red'}), row=1, col=1)\n",
    "for ai in [f for f in detection_detect_table.columns if 'anomaly_indicator' in f]:\n",
    "    fig.add_trace(go.Scatter(x=detection_detect_table['timestamp'], y=detection_detect_table[ai], name= ai.replace('anomaly_indicator_','')+' OutOfSample'), row=2, col=1)\n",
    "    va = detection_detect_table[detection_detect_table[ai]>=1]\n",
    "    fig.add_trace(go.Scatter(x=va['timestamp'], y=va['kpi'], name=ai.replace('anomaly_indicator_','')+' anomaly outOfSample',mode='markers', line={'color': 'red'}), row=1, col=1)\n",
    "fig.add_hline(y=1, line_color=\"orange\", row=2, col=1)\n",
    "fig.update_layout(height=700, width=1400, title_text=\"Results\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90100a33-b9f0-459c-b45e-0c7f0b8bfeae",
   "metadata": {},
   "source": [
    "## 3.2 Anomaly List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3736b7ee-b0d1-43a4-bd1d-0520781e3ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_index</th>\n",
       "      <th>kpi</th>\n",
       "      <th>normal_behavior</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>anomaly_indicator_residual</th>\n",
       "      <th>anomaly_indicator_imbalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2019-03-06 11:03:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.855126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.212612</td>\n",
       "      <td>0.376316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2019-03-06 11:11:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.555792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.664308</td>\n",
       "      <td>0.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>2019-03-06 11:11:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.581634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.222966</td>\n",
       "      <td>0.134751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>2019-03-06 11:11:31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>1.353532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.070858</td>\n",
       "      <td>0.584259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>2019-03-06 11:21:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1.425940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.069886</td>\n",
       "      <td>0.597299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>2019-03-06 14:46:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.127911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.580257</td>\n",
       "      <td>1.022099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>2019-03-06 14:46:31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.150170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.524101</td>\n",
       "      <td>1.037345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>2019-03-06 14:46:32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.146576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.470794</td>\n",
       "      <td>1.043201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>2019-03-06 14:46:33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.129912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488658</td>\n",
       "      <td>1.019313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>2019-03-06 14:46:34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.125827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.471355</td>\n",
       "      <td>1.003488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp  model_index   kpi  normal_behavior  anomaly  \\\n",
       "638  2019-03-06 11:03:11          1.0  3.45         0.855126      1.0   \n",
       "1107 2019-03-06 11:11:01          1.0  0.00         3.555792      1.0   \n",
       "1109 2019-03-06 11:11:03          1.0  3.72         0.581634      1.0   \n",
       "1137 2019-03-06 11:11:31          1.0  3.18         1.353532      1.0   \n",
       "1756 2019-03-06 11:21:50          1.0  3.42         1.425940      1.0   \n",
       "...                  ...          ...   ...              ...      ...   \n",
       "4638 2019-03-06 14:46:30          1.0  3.42         3.127911      1.0   \n",
       "4639 2019-03-06 14:46:31          1.0  3.42         3.150170      1.0   \n",
       "4640 2019-03-06 14:46:32          1.0  3.38         3.146576      1.0   \n",
       "4641 2019-03-06 14:46:33          1.0  3.38         3.129912      1.0   \n",
       "4642 2019-03-06 14:46:34          1.0  3.36         3.125827      1.0   \n",
       "\n",
       "      anomaly_indicator_residual  anomaly_indicator_imbalance  \n",
       "638                     1.212612                     0.376316  \n",
       "1107                    1.664308                     0.212900  \n",
       "1109                    1.222966                     0.134751  \n",
       "1137                    1.070858                     0.584259  \n",
       "1756                    1.069886                     0.597299  \n",
       "...                          ...                          ...  \n",
       "4638                    0.580257                     1.022099  \n",
       "4639                    0.524101                     1.037345  \n",
       "4640                    0.470794                     1.043201  \n",
       "4641                    0.488658                     1.019313  \n",
       "4642                    0.471355                     1.003488  \n",
       "\n",
       "[61 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_table = pd.concat([detection_build_kpi_model_table,detection_detect_table])\n",
    "anomaly_list_df = detection_table[detection_table['anomaly_code'].isin([1,3])].copy().rename(columns={'anomaly_code':'anomaly'})\n",
    "anomaly_list_df['timestamp'] = pd.to_datetime(anomaly_list_df['timestamp'],format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "anomaly_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f85db1-479c-4b7e-9b2b-6144be0a74f9",
   "metadata": {},
   "source": [
    "## 3.3 Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35980570-5a7f-4d63-9b37-061c424276ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = go.Figure(go.Bar(x=properties_df['name'], y=properties_df['rel_importance'],text=round(properties_df['rel_importance'],2),textposition='auto'))\n",
    "fig1.update_layout(height=500,width=1200,title_text='Predictor Importances',xaxis_title='name',yaxis_title='rel_importance')\n",
    "print('Predictors not used:'+str(list(set(predictors+[target])-set(list(properties_df['name'])))))\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d6b52-fda4-4c66-b424-32427b815327",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(features_df, path=['Model','Feature'], values='importance',color='Feature')\n",
    "fig.update_layout(height=700,width=700,title_text='Feature Importances')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a649fb7-b8f6-4af6-a6e1-d2c0294cb229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings = list(model_logs_df[model_logs_df['messageType'] == \"Warning\"]['message'])\n",
    "warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af40eda6-5cd0-4f50-ba5f-8c3bede857c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>messageType</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The job is categorized as light.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:48.768Z</td>\n",
       "      <td>Registration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expected result table size is 0.87 MiB.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:48.768Z</td>\n",
       "      <td>Registration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job waiting in queue with priority 4.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:49.065Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Executing job.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:49.126Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detection job, type: model building, approach:...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:49.296Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Getting data from dataset version \"0d01f203-47...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:49.431Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Used sampling period 1 second.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:50.689Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Validation successful.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:50.758Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Building the normal behavior model.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:50.771Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parameter useKPIoffsets is set to true. Reason...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:50.803Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TIM will consider this dataset to be nondaily-...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:50.813Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Offset limit set to -1.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:51.276Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Turned off rest of the week transformation, to...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:51.323Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Turned off public holidays transformation.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:52.235Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Building the anomalous behavior model.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:53.327Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Creating anomaly detection results.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:59.094Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Saving results.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:59.214Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Table result saved. Size of the stored data is...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:59.227Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Model saved. Size of the stored data is 32747 ...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:59.227Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Execution finished.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-04-20T15:26:59.741Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message messageType  \\\n",
       "0                    The job is categorized as light.        Info   \n",
       "1             Expected result table size is 0.87 MiB.        Info   \n",
       "2               Job waiting in queue with priority 4.        Info   \n",
       "3                                      Executing job.        Info   \n",
       "4   Detection job, type: model building, approach:...        Info   \n",
       "5   Getting data from dataset version \"0d01f203-47...        Info   \n",
       "6                      Used sampling period 1 second.        Info   \n",
       "7                              Validation successful.        Info   \n",
       "8                 Building the normal behavior model.        Info   \n",
       "9   Parameter useKPIoffsets is set to true. Reason...        Info   \n",
       "10  TIM will consider this dataset to be nondaily-...        Info   \n",
       "11                            Offset limit set to -1.        Info   \n",
       "12  Turned off rest of the week transformation, to...        Info   \n",
       "13         Turned off public holidays transformation.        Info   \n",
       "14             Building the anomalous behavior model.        Info   \n",
       "15                Creating anomaly detection results.        Info   \n",
       "16                                    Saving results.        Info   \n",
       "17  Table result saved. Size of the stored data is...        Info   \n",
       "18  Model saved. Size of the stored data is 32747 ...        Info   \n",
       "19                                Execution finished.        Info   \n",
       "\n",
       "                   createdAt        origin  \n",
       "0   2023-04-20T15:26:48.768Z  Registration  \n",
       "1   2023-04-20T15:26:48.768Z  Registration  \n",
       "2   2023-04-20T15:26:49.065Z     Execution  \n",
       "3   2023-04-20T15:26:49.126Z     Execution  \n",
       "4   2023-04-20T15:26:49.296Z     Execution  \n",
       "5   2023-04-20T15:26:49.431Z     Execution  \n",
       "6   2023-04-20T15:26:50.689Z     Execution  \n",
       "7   2023-04-20T15:26:50.758Z     Execution  \n",
       "8   2023-04-20T15:26:50.771Z     Execution  \n",
       "9   2023-04-20T15:26:50.803Z     Execution  \n",
       "10  2023-04-20T15:26:50.813Z     Execution  \n",
       "11  2023-04-20T15:26:51.276Z     Execution  \n",
       "12  2023-04-20T15:26:51.323Z     Execution  \n",
       "13  2023-04-20T15:26:52.235Z     Execution  \n",
       "14  2023-04-20T15:26:53.327Z     Execution  \n",
       "15  2023-04-20T15:26:59.094Z     Execution  \n",
       "16  2023-04-20T15:26:59.214Z     Execution  \n",
       "17  2023-04-20T15:26:59.227Z     Execution  \n",
       "18  2023-04-20T15:26:59.227Z     Execution  \n",
       "19  2023-04-20T15:26:59.741Z     Execution  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1cca5bda-06de-471a-9c45-644b40ce4a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>messageType</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The job is categorized as light.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:44.674Z</td>\n",
       "      <td>Registration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expected result table size is 0.43 MiB.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:44.674Z</td>\n",
       "      <td>Registration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queued by fa4b9fce-f6f6-4f07-bab1-5814a537c413.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:44.991Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job execution posted to queue with priority 5.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:47.280Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Handling request ...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:47.310Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Executing job \"663816be-9a87-410a-b39b-f6b32b2...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:47.338Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anomaly detection job, type: detection., appro...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:47.596Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Getting resources from the parent job \"aa100d3...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:47.609Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Used sampling period 1 second.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:49.113Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Validation successful.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:49.162Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Applying model for detection.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:49.428Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Creating anomaly detection results.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:50.055Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Saving results.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:50.451Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Table result saved. Size of the stored data is...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:50.462Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Execution finished.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-02-06T13:52:50.822Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message messageType  \\\n",
       "0                    The job is categorized as light.        Info   \n",
       "1             Expected result table size is 0.43 MiB.        Info   \n",
       "2     Queued by fa4b9fce-f6f6-4f07-bab1-5814a537c413.        Info   \n",
       "3      Job execution posted to queue with priority 5.        Info   \n",
       "4                                Handling request ...        Info   \n",
       "5   Executing job \"663816be-9a87-410a-b39b-f6b32b2...        Info   \n",
       "6   Anomaly detection job, type: detection., appro...        Info   \n",
       "7   Getting resources from the parent job \"aa100d3...        Info   \n",
       "8                      Used sampling period 1 second.        Info   \n",
       "9                              Validation successful.        Info   \n",
       "10                      Applying model for detection.        Info   \n",
       "11                Creating anomaly detection results.        Info   \n",
       "12                                    Saving results.        Info   \n",
       "13  Table result saved. Size of the stored data is...        Info   \n",
       "14                                Execution finished.        Info   \n",
       "\n",
       "                   createdAt        origin  \n",
       "0   2023-02-06T13:52:44.674Z  Registration  \n",
       "1   2023-02-06T13:52:44.674Z  Registration  \n",
       "2   2023-02-06T13:52:44.991Z     Execution  \n",
       "3   2023-02-06T13:52:47.280Z     Execution  \n",
       "4   2023-02-06T13:52:47.310Z     Execution  \n",
       "5   2023-02-06T13:52:47.338Z     Execution  \n",
       "6   2023-02-06T13:52:47.596Z     Execution  \n",
       "7   2023-02-06T13:52:47.609Z     Execution  \n",
       "8   2023-02-06T13:52:49.113Z     Execution  \n",
       "9   2023-02-06T13:52:49.162Z     Execution  \n",
       "10  2023-02-06T13:52:49.428Z     Execution  \n",
       "11  2023-02-06T13:52:50.055Z     Execution  \n",
       "12  2023-02-06T13:52:50.451Z     Execution  \n",
       "13  2023-02-06T13:52:50.462Z     Execution  \n",
       "14  2023-02-06T13:52:50.822Z     Execution  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceefca62-1720-42f8-b016-91d4195cf567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
